{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 7: Implementing a Convolutional Neural Network Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" # suppress info and warning messages\n",
    "import tensorflow.keras as keras\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very common problem in computer vision is recognizing hand-written digits. The images of numerals are commonly used by data scientists and machine learning experts to train supervised learning models that specialize in decoding human handwriting. This is a classic problem that is often used in exercises and documentation. In this lab, you will train a convolutional neural network to classify hand-written digits. You will complete the following tasks:\n",
    "\n",
    "1. Define your ML problem:\n",
    "    * Define the label - what are you predicting?\n",
    "    * Identify the features\n",
    "2. Import the data and split the data into training and test data sets\n",
    "3. Inspect and visualize the data\n",
    "3. Prepare your data so that it is ready for modeling.\n",
    "5. Construct a convolutional neural network\n",
    "6. Train the convolutional neural network.\n",
    "7. Evaluate the neural network model's performance on the training and test data.\n",
    "\n",
    "For this lab, use the demo <i>Implementing a Neural Network Using Keras</i> that is contained in this unit as a reference.\n",
    "\n",
    "**<font color='red'>Note: some of the code cells in this notebook may take a while to run</font>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Define Your ML Problem \n",
    "\n",
    "We will implement a convolutional neural network to solve a handwriting recognition problem. The neural network will classify a hand-written digit. \n",
    "\n",
    "#### Define the Label\n",
    "\n",
    "We will work with the MNIST data set, a famous collection of images used for handwriting recognition. It contains labeled images of handwritten digits from 0 to 9. Therefore, the label is a digit from 0 and 9. This is a multiclass classification problem. \n",
    "\n",
    "\n",
    "#### Identify Features\n",
    "\n",
    "Each example corresponds to one hand-written image. The features will be comprised of numerical feature vectors (an n-dimensional array) that contain grey-scale pixel values that range from 0 to 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Import the Data Set and Create Training and Test Sets\n",
    "\n",
    "The MNIST data set comes preloaded in Keras. The `load_data()` function returns the data set split into training and test subsets. The cell below loads the data set and contains training and test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mnist data set comes preloaded \n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# Create training and test sets\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, inspect the datatype and dimensions (shape) of the training and test data (`X_train`, `y_train`, `X_test`, `y_test`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train is of type: <class 'numpy.ndarray'>, and shape: (60000, 28, 28)\n",
      "y_train is of type: <class 'numpy.ndarray'>, and shape: (60000,)\n",
      "X_test is of type: <class 'numpy.ndarray'>, and shape: (10000, 28, 28)\n",
      "y_test is of type: <class 'numpy.ndarray'>, and shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train is of type: {type(X_train)}, and shape: {X_train.shape}\")\n",
    "\n",
    "print(f\"y_train is of type: {type(y_train)}, and shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"X_test is of type: {type(X_test)}, and shape: {X_test.shape}\")\n",
    "\n",
    "print(f\"y_test is of type: {type(y_test)}, and shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training and test data sets are NumPy arrays. \n",
    "\n",
    "* <b>Training data:</b><br>\n",
    "    `X_train` is a three-dimensional array of shape `(60000, 28, 28)`. It contains grayscale image data. Pixel values range from 0 to 255.<br>\n",
    "    `y_train` is a one-dimensional array with shape `(6000,)`. It contains digit labels (integers in range 0-9).\n",
    "\n",
    "\n",
    "* <b>Test data:</b><br>\n",
    "    `X_test` is a three-dimensional array of shape `(10000, 28, 28)`. It contains grayscale image data. Pixel values range from 0 to 255.<br>`y_test` is a one-dimensional array with shape `(1000,)`. It contains digit labels (integers in range 0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data in more detail. Let's inspect the first example (which contains an image) in `X_train`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the first example in the training data is a 28 x 28 array.  This array encodes the grayscale value of the  hand-written image, i.e., each entry in the 28 x 28 array encodes the intensity (darkness) of the corresponding pixel. \n",
    "\n",
    "### Visualize the Data\n",
    "\n",
    "Let's visualize an image below.\n",
    "\n",
    "<b>Task</b>: In the code cell below, use the Seaborn`heatmap()` function to display any image contained in `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 0\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "sns.heatmap(X_train[image_index], cmap = 'gray', cbar = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Inspect the corresponding label in `y_train` to confirm that the label matches the image you see in the heatmap above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label for the image at index 0 is: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"The label for the image at index {image_index} is: {y_train[image_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Which digit appeared in your heatmap? Did it match its label? Record your findings in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digit that appeared in my heatmap is 5, it matched its label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a function `plot_imgs()` to help us visualize the image data. Let's use this function to inspect a few more examples in the training data. Execute the two code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the data\n",
    "def plot_imgs(images, labels=None):\n",
    "    subplots_x = int(math.ceil(len(images) / 5))\n",
    "    plt.figure(figsize=(10,2*subplots_x))\n",
    "    for i in range(min(len(images), subplots_x*5)):\n",
    "        plt.subplot(subplots_x,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        if labels is not None:\n",
    "            plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some training examples\n",
    "plot_imgs(X_train[:8], y_train[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now prepare our data to be suitable for a CNN.\n",
    "\n",
    "#### Scale the Data\n",
    "\n",
    "Our MNIST data is raw data containing pixel values between 0 and 255. Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the training process. Therefore, it is a good practice to normalize the pixel values so that each pixel has a value between 0 and 1. This can be done by dividing all pixels values by the largest pixel value; that is 255. \n",
    "\n",
    "<b>Task:</b> In the code cell below, normalize the pixel values in `X_train` and `X_test` to be between 0 and 1 by dividing all feature values by 255.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0\n",
    "X_train_normalized\n",
    "X_test_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the Data\n",
    "A CNN in Keras requires a 4-dimensional array as input in the form: `(num_examples, image_dimension_X, image_dimension_Y, num_channels)`.\n",
    "\n",
    "Since grayscale has only one color channel, every example in `X_train` would have the shape `(28, 28, 1)`. `X_test` should have the same dimensions.\n",
    "\n",
    "<b>Task:</b> In the code cell below: \n",
    "1. reshape every example in `X_train` to have the shape `(num_examples_X_train, 28, 28, 1)`.\n",
    "1. reshape every example in `X_test` to have the shape `(num_examples_X_test, 28, 28, 1)`.\n",
    "\n",
    "<i>Hint:</i> use the NumPy `reshape()` function. Consult the online [documentation](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train reshaped: (60000, 28, 28, 1)\n",
      "X_test reshaped: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_reshaped = np.reshape(X_train_normalized, (X_train_normalized.shape[0], 28, 28, 1))\n",
    "X_test_reshaped = np.reshape(X_test_normalized, (X_test_normalized.shape[0], 28, 28, 1))\n",
    "\n",
    "print(f\"X_train reshaped: {X_train_reshaped.shape}\")\n",
    "print(f\"X_test reshaped: {X_test_reshaped.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Construct the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Define Model Structure\n",
    "\n",
    "Next we will create our convolutional neural network structure. A CNN has three different types of hidden layers: a convolutional layer, a pooling layer, and a fully connected layer. When constructing a convolutional hidden layer, we will compose a 2D convolution, followed by a batch normalization, followed by an activation function. \n",
    "\n",
    "Let's create the CNN structure (Note that there are different ways one can choose to construct a CNN in Keras). We will create an input layer, five hidden layers and an output layer:\n",
    "\n",
    "* <b>Input layer</b>: The input layer will have the input shape corresponding to the number of features. \n",
    "* <b>Hidden layers</b>: We will create five hidden layers:\n",
    "    * Four hidden layers will be convolutional layers. They will be comprised of a 2D convolution, followed by a batch normalization, followed by an activation function. In this case, the activation function of choice is ReLU.\n",
    "    * One hidden layer will be a pooling layer. We will add a layer that uses Global Average Pooling. This is a pooling operation designed to replace the final fully connected layer in classical CNN. \n",
    "* <b>Output layer</b>: The output layer will have a width of 10. \n",
    "\n",
    "To construct the CNN model using Keras, we will do the following:\n",
    "\n",
    "* As before, we will use the Keras `Sequential` class to group a stack of layers. This will be our CNN model object. For more information, consult the Keras online [Sequential class documentation](https://keras.io/api/models/sequential/#sequential-class).\n",
    "* We will use the `InputLayer` class to create the input layer. For more information, consult the Keras online [InputLayer class documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer).\n",
    "* We will use the `Conv2D` class to create the convolutional layers. For more information, consult the Keras online [Conv2D class documentation](https://keras.io/api/layers/convolution_layers/convolution2d/).\n",
    "    * For batch normalization, we will use the `BatchNormalization` class. For more information, consult the Keras online [BatchNormalization class documentation](https://keras.io/api/layers/normalization_layers/batch_normalization/).\n",
    "    * For the activation function, we will use the `ReLU` class. For more information, consult the Keras online [ReLU class documentation](https://keras.io/api/layers/activation_layers/relu/).\n",
    "* We will use the `GlobalAveragePooling2D` class to create the pooling layer. For more information, consult the Keras online [GlobalAveragePooling2D class documentation](https://keras.io/api/layers/pooling_layers/global_average_pooling2d/\n",
    ").\n",
    "* Finally, we will use the `Dense` class to create the output layer. For more information, consult the Keras online [Dense class documentation](https://keras.io/api/layers/core_layers/dense/).\n",
    "* We will add each layer to the CNN model object.\n",
    "\n",
    "\n",
    "<b>Task:</b> Follow these steps to complete the code in the cell below:\n",
    "\n",
    "1. Create the CNN model object. \n",
    "    * Use ``keras.Sequential() `` to create a model object, and assign the result to the variable ```cnn_model```.\n",
    "    \n",
    "      \n",
    "2. Create the input layer: \n",
    "    * Call `keras.layers.InputLayer()` with the argument `input_shape` to specify the dimensions of the input. In this case, the dimensions will be the shape of each example (image) in `X_train` &mdash; assign this value to the argument `input_shape`. \n",
    "    * Assign the result to the variable `input_layer`.\n",
    "    * Add `input_layer` to the neural network model object `cnn_model`.\n",
    "    \n",
    "\n",
    "3. Create the first convolutional layer. You will accomplish this by doing the following:\n",
    "    * Call `keras.layers.Conv2D()` and assign the result to the variable `conv_1`. You will pass two arguments to `Conv2D()`:\n",
    "        1. The number of filters: `Conv2D()` requires an argument indicating the number of filters in the convolution. Layers in the network architecture that are closer to the input layer learn fewer convolutional filters whereas layers closer to the output layer learn more filters. Let's choose a value of 16 for the first layer. \n",
    "        2. The kernal size: this argument specifies the size of the convolution window. We will choose a kernal size of 3.\n",
    "    * Call `keras.layers.BatchNormalization()` without arguments. Assign the result to variable `batchNorm_1`.\n",
    "    * Call `keras.layers.ReLU()` without arguments. Assign the result to avariable `ReLU_1`.    \n",
    "    * Add each of these items (`conv_1`, `batchNorm_1` and `ReLU_1`) in order to the neural network model object `cnn_model`.\n",
    "    \n",
    "\n",
    "4. Create the second convolutional layer using the same approach that you used to create the first convolutional layer, specifying 32 filters and a kernal size of 3. Add the layer to the neural network model object `cnn_model`.\n",
    "\n",
    "    \n",
    "5. Create the third convolutional layer using the same approach that you used to create the first convolutional layer, specifying 64 filters and a kernal size of 3. Add the layer to the neural network model object `cnn_model`.\n",
    "\n",
    "    \n",
    "6. Create the fourth convolutional layer using the same approach that you used to create the first convolutional layer, specifying 128 filters and a kernal size of 3. Add the layer to the neural network model object `cnn_model`. \n",
    "\n",
    "    \n",
    "7. Create the pooling layer:\n",
    "    * Call `keras.layers.GlobalAveragePooling2D()` without arguments.\n",
    "    * Assign the result to the variable `pooling_layer`.\n",
    "    * Add `pooling_layer` to the neural network model object `cnn_model`. \n",
    "  \n",
    "  \n",
    "8. Create the output layer:\n",
    "    * Call `keras.layers.Dense()`. We will have one node per class. We have ten classes (digits from 0-9). Therefore, when creating the output later, specify 10 units. Do not specify an activation function.\n",
    "    * Assign the result to the variable `output_layer`.\n",
    "    * Add `output_layer` to the neural network model object `cnn_model`. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 16)        64        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 99,402\n",
      "Trainable params: 98,922\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. Create CNN model object\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense\n",
    "\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# 2. Create the input layer and add it to the model object: \n",
    "input_layer = InputLayer(input_shape=(28, 28, 1))\n",
    "cnn_model.add(input_layer)\n",
    "\n",
    "# 3. Create the first convolutional layer and add it to the model object:\n",
    "conv_1 = Conv2D(16, kernel_size = 3)\n",
    "cnn_model.add(conv_1)\n",
    "batchNorm_1 = BatchNormalization()\n",
    "cnn_model.add(batchNorm_1)\n",
    "ReLU_1 = ReLU()\n",
    "cnn_model.add(ReLU_1)\n",
    "\n",
    "# 4. Create the second convolutional layer and add it to the model object:\n",
    "conv_2 = Conv2D(32, kernel_size = 3)\n",
    "cnn_model.add(conv_2)\n",
    "batchNorm_2 = BatchNormalization()\n",
    "cnn_model.add(batchNorm_2)\n",
    "ReLU_2 = ReLU()\n",
    "cnn_model.add(ReLU_2)\n",
    "\n",
    "# 5. Create the third convolutional layer and add it to the model object:\n",
    "conv_3 = Conv2D(64, kernel_size = 3)\n",
    "cnn_model.add(conv_3)\n",
    "batchNorm_3 = BatchNormalization()\n",
    "cnn_model.add(batchNorm_3)\n",
    "ReLU_3 = ReLU()\n",
    "cnn_model.add(ReLU_3)\n",
    "\n",
    "# 6. Create the fourth convolutional layer and add it to the model object:\n",
    "conv_4 = Conv2D(128, kernel_size = 3)\n",
    "cnn_model.add(conv_4)\n",
    "batchNorm_4 = BatchNormalization()\n",
    "cnn_model.add(batchNorm_4)\n",
    "ReLU_4 = ReLU()\n",
    "cnn_model.add(ReLU_4)\n",
    "\n",
    "# 7. Create the pooling layer and add it to the model object:\n",
    "pooling_layer = GlobalAveragePooling2D()\n",
    "cnn_model.add(pooling_layer)\n",
    "\n",
    "# 8. Create the output layer and add it to the model object:\n",
    "output_layer = Dense(10)\n",
    "cnn_model.add(output_layer)\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Define the Optimization Function\n",
    "\n",
    "<b>Task:</b> In the code cell below, create a stochastic gradient descent optimizer using  `keras.optimizers.SGD()`. Specify a learning rate of 0.1 using the `learning_rate` parameter. Assign the result to the variable`sgd_optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "sgd_optimizer = SGD(learning_rate = 0.1)\n",
    "sgd_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Define the loss function\n",
    "\n",
    "<b>Task:</b> In the code cell below, create a sparse categorical cross entropy loss function using `keras.losses.SparseCategoricalCrossentropy()`. This is an extension of the categorical cross entropy loss function. It is used when there are two or more label classes and the labels are integers. For more information, consult the online [SparseCategoricalCrossentropy documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy). Use the parameter `from_logits=True`. Assign the result to the variable  `loss_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "loss_fn = SparseCategoricalCrossentropy(from_logits = True)\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Compile the model\n",
    "\n",
    "<b>Task:</b> In the code cell below, package the network architecture with the optimizer and the loss function using the `cnn_model.compile()` method. Specify the optimizer, loss function and the accuracy evaluation metric as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer = sgd_optimizer, loss = loss_fn, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Fit the Model to the Training Data\n",
    "\n",
    "We can now fit the CNN model to the training data. Since there are 60,000 training examples and nearly 100,000 parameters to fit, this may take a while to run. Therefore, we will only choose one epoch in this assignment.\n",
    "\n",
    "<b>Task:</b> In the code cell below, fit the CNN model to the training data using the `fit()` method. Call `cnn_model.fit()` with the following arguments:\n",
    "1. The training data sets.\n",
    "2. The number of epochs.\n",
    "\n",
    "Save the results to the variable `history`. \n",
    "\n",
    "<b>Note</b>: This may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 69s 36ms/step - loss: 0.3402 - accuracy: 0.9173\n",
      "Elapsed time: 69.11s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1 # Number of epochs\n",
    "\n",
    "t0 = time.time() # start time\n",
    "\n",
    "history = cnn_model.fit(X_train_reshaped, y_train, epochs = num_epochs) \n",
    "\n",
    "t1 = time.time() # stop time\n",
    "\n",
    "print('Elapsed time: %.2fs' % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. Evaluate the Model's Performance\n",
    "\n",
    "Let's now evaluate our CNN model's performance on our test data and see how it did.\n",
    "\n",
    "\n",
    "<b>Task:</b> In the code cell below, call the `cnn_model.evaluate()` method with the test data sets as arguments. The `evaluate()` method returns a list containing two values. The first value is the loss and the second value is the accuracy score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.1518 - accuracy: 0.9589\n",
      "Loss:  0.1518343836069107 Accuracy:  0.958899974822998\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn_model.evaluate(X_test_reshaped, y_test)\n",
    "\n",
    "print('Loss: ', str(loss) , 'Accuracy: ', str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll make some predictions on the test set and see for ourselves how accurate these predictions are.\n",
    "\n",
    "<b>Task:</b> In the code cell below, call the `plot_imgs()` functions with the first 25 images in `X_test` as the first argument, and the first 25 labels in `predictions` as the second argument. \n",
    "\n",
    "The result should be a display of the first 25 images in the test set `X_test`, and below each image, a display of the predicted digit. How well did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:230 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## Plot individual predictions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Defines the plot_imgs function\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1727\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1726\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1727\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1728\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1729\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    767\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3050\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3050\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3444\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3441\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3444\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3279\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3274\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3276\u001b[0m ]\n\u001b[1;32m   3277\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3278\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3282\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3287\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3288\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3291\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3292\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3293\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3294\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3295\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3296\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:999\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 999\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1004\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:672\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    670\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 672\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    985\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    987\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:230 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "logits = cnn_model.predict(X_test)\n",
    "predictions = logits.argmax(axis = 1)\n",
    "\n",
    "\n",
    "## Plot individual predictions\n",
    "# Defines the plot_imgs function\n",
    "def plot_imgs(images, labels):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap = plt.cm.binary)\n",
    "        plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "\n",
    "# Call the plot_imgs function with the first 25 images in X_test and the first 25 labels in predictions\n",
    "plot_imgs(X_test[:25], predictions[:25])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
